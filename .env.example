# Memento MCP Environment Configuration Example
# Copy this file to .env and update with your values

# Embedding Provider Selection
# Options: azure, openai, ollama (auto-detects if not specified)
EMBEDDING_PROVIDER=azure

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your-azure-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2023-05-15
AZURE_OPENAI_MODEL=text-embedding-ada-002

# OpenAI Configuration (as fallback or primary)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama Configuration (for local embeddings)
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=nomic-embed-text

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=memento_password

# Testing Configuration
# Set to true to use mock embeddings (no API calls)
# MOCK_EMBEDDINGS=false

# Enable debug mode for verbose logging
# DEBUG=true

# Query Preprocessing Configuration
# Enable enhanced multi-term query preprocessing for semantic search
# When enabled, improves search results for multi-term queries through:
# - Adaptive similarity thresholds based on query complexity
# - Query decomposition for compound concepts
# - Enhanced fallback patterns from actual query terms
# Default: false (preserves original behavior)
ENABLE_QUERY_PREPROCESSING=false